torch.cuda.memory.caching_allocator_enable 
==========================================================================================================================

torch.cuda.memory. caching_allocator_enable ( *value = True* ) [source](https://github.com/pytorch/pytorch/blob/v2.8.0/torch/cuda/memory.py#L163) 
:   Enable or disable the CUDA memory allocator. On by default.

