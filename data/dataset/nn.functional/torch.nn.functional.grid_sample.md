torch.nn.functional.grid_sample 
===================================================================================================

torch.nn.functional. grid_sample ( *input*  , *grid*  , *mode = 'bilinear'*  , *padding_mode = 'zeros'*  , *align_corners = None* ) [source](https://github.com/pytorch/pytorch/blob/v2.8.0/torch/nn/functional.py#L4948) 
:   Compute grid sample. 

Given an `input`  and a flow-field `grid`  , computes the `output`  using `input`  values and pixel locations from `grid`  . 

Currently, only spatial (4-D) and volumetric (5-D) `input`  are
supported. 

In the spatial (4-D) case, for `input`  with shape <!-- MathML: <math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mo stretchy="false">
            (
           </mo>
<mi>
            N
           </mi>
<mo separator="true">
            ,
           </mo>
<mi>
            C
           </mi>
<mo separator="true">
            ,
           </mo>
<msub>
<mi>
             H
            </mi>
<mtext>
             in
            </mtext>
</msub>
<mo separator="true">
            ,
           </mo>
<msub>
<mi>
             W
            </mi>
<mtext>
             in
            </mtext>
</msub>
<mo stretchy="false">
            )
           </mo>
</mrow>
<annotation encoding="application/x-tex">
           (N, C, H_text{in}, W_text{in})
          </annotation>
</semantics>
</math> -->( N , C , H in , W in ) (N, C, H_text{in}, W_text{in})( N , C , H in ​ , W in ​ )  and `grid`  with shape <!-- MathML: <math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mo stretchy="false">
            (
           </mo>
<mi>
            N
           </mi>
<mo separator="true">
            ,
           </mo>
<msub>
<mi>
             H
            </mi>
<mtext>
             out
            </mtext>
</msub>
<mo separator="true">
            ,
           </mo>
<msub>
<mi>
             W
            </mi>
<mtext>
             out
            </mtext>
</msub>
<mo separator="true">
            ,
           </mo>
<mn>
            2
           </mn>
<mo stretchy="false">
            )
           </mo>
</mrow>
<annotation encoding="application/x-tex">
           (N, H_text{out}, W_text{out}, 2)
          </annotation>
</semantics>
</math> -->( N , H out , W out , 2 ) (N, H_text{out}, W_text{out}, 2)( N , H out ​ , W out ​ , 2 )  , the output will have shape <!-- MathML: <math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mo stretchy="false">
            (
           </mo>
<mi>
            N
           </mi>
<mo separator="true">
            ,
           </mo>
<mi>
            C
           </mi>
<mo separator="true">
            ,
           </mo>
<msub>
<mi>
             H
            </mi>
<mtext>
             out
            </mtext>
</msub>
<mo separator="true">
            ,
           </mo>
<msub>
<mi>
             W
            </mi>
<mtext>
             out
            </mtext>
</msub>
<mo stretchy="false">
            )
           </mo>
</mrow>
<annotation encoding="application/x-tex">
           (N, C, H_text{out}, W_text{out})
          </annotation>
</semantics>
</math> -->( N , C , H out , W out ) (N, C, H_text{out}, W_text{out})( N , C , H out ​ , W out ​ )  . 

For each output location `output[n, :, h, w]`  , the size-2 vector `grid[n, h, w]`  specifies `input`  pixel locations `x`  and `y`  ,
which are used to interpolate the output value `output[n, :, h, w]`  .
In the case of 5D inputs, `grid[n, d, h, w]`  specifies the `x`  , `y`  , `z`  pixel locations for interpolating `output[n, :, d, h, w]`  . `mode`  argument specifies `nearest`  or `bilinear`  interpolation method to sample the input pixels. 

`grid`  specifies the sampling pixel locations normalized by the `input`  spatial dimensions. Therefore, it should have most values in
the range of `[-1, 1]`  . For example, values `x = -1, y = -1`  is the
left-top pixel of `input`  , and values `x = 1, y = 1`  is the
right-bottom pixel of `input`  . 

If `grid`  has values outside the range of `[-1, 1]`  , the corresponding
outputs are handled as defined by `padding_mode`  . Options are 

> * `padding_mode="zeros"`  : use `0`  for out-of-bound grid locations,
> * `padding_mode="border"`  : use border values for out-of-bound grid locations,
> * `padding_mode="reflection"`  : use values at locations reflected by
> the border for out-of-bound grid locations. For location far away
> from the border, it will keep being reflected until becoming in bound,
> e.g., (normalized) pixel location `x = -3.5`  reflects by border `-1`  and becomes `x' = 1.5`  , then reflects by border `1`  and becomes `x'' = -0.5`  .

Note 

This function is often used in conjunction with [`affine_grid()`](torch.nn.functional.affine_grid.html#torch.nn.functional.affine_grid "torch.nn.functional.affine_grid")  to build [Spatial Transformer Networks](https://arxiv.org/abs/1506.02025)  .

Note 

When using the CUDA backend, this operation may induce nondeterministic
behaviour in its backward pass that is not easily switched off.
Please see the notes on [Reproducibility](../notes/randomness.html)  for background.

Note 

NaN values in `grid`  would be interpreted as `-1`  .

Parameters
:   * **input** ( [*Tensor*](../tensors.html#torch.Tensor "torch.Tensor")  ) – input of shape <!-- MathML: <math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mo stretchy="false">
                (
               </mo>
<mi>
                N
               </mi>
<mo separator="true">
                ,
               </mo>
<mi>
                C
               </mi>
<mo separator="true">
                ,
               </mo>
<msub>
<mi>
                 H
                </mi>
<mtext>
                 in
                </mtext>
</msub>
<mo separator="true">
                ,
               </mo>
<msub>
<mi>
                 W
                </mi>
<mtext>
                 in
                </mtext>
</msub>
<mo stretchy="false">
                )
               </mo>
</mrow>
<annotation encoding="application/x-tex">
               (N, C, H_text{in}, W_text{in})
              </annotation>
</semantics>
</math> -->( N , C , H in , W in ) (N, C, H_text{in}, W_text{in})( N , C , H in ​ , W in ​ )  (4-D case)
or <!-- MathML: <math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mo stretchy="false">
                (
               </mo>
<mi>
                N
               </mi>
<mo separator="true">
                ,
               </mo>
<mi>
                C
               </mi>
<mo separator="true">
                ,
               </mo>
<msub>
<mi>
                 D
                </mi>
<mtext>
                 in
                </mtext>
</msub>
<mo separator="true">
                ,
               </mo>
<msub>
<mi>
                 H
                </mi>
<mtext>
                 in
                </mtext>
</msub>
<mo separator="true">
                ,
               </mo>
<msub>
<mi>
                 W
                </mi>
<mtext>
                 in
                </mtext>
</msub>
<mo stretchy="false">
                )
               </mo>
</mrow>
<annotation encoding="application/x-tex">
               (N, C, D_text{in}, H_text{in}, W_text{in})
              </annotation>
</semantics>
</math> -->( N , C , D in , H in , W in ) (N, C, D_text{in}, H_text{in}, W_text{in})( N , C , D in ​ , H in ​ , W in ​ )  (5-D case)

* **grid** ( [*Tensor*](../tensors.html#torch.Tensor "torch.Tensor")  ) – flow-field of shape <!-- MathML: <math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mo stretchy="false">
                (
               </mo>
<mi>
                N
               </mi>
<mo separator="true">
                ,
               </mo>
<msub>
<mi>
                 H
                </mi>
<mtext>
                 out
                </mtext>
</msub>
<mo separator="true">
                ,
               </mo>
<msub>
<mi>
                 W
                </mi>
<mtext>
                 out
                </mtext>
</msub>
<mo separator="true">
                ,
               </mo>
<mn>
                2
               </mn>
<mo stretchy="false">
                )
               </mo>
</mrow>
<annotation encoding="application/x-tex">
               (N, H_text{out}, W_text{out}, 2)
              </annotation>
</semantics>
</math> -->( N , H out , W out , 2 ) (N, H_text{out}, W_text{out}, 2)( N , H out ​ , W out ​ , 2 )  (4-D case)
or <!-- MathML: <math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mo stretchy="false">
                (
               </mo>
<mi>
                N
               </mi>
<mo separator="true">
                ,
               </mo>
<msub>
<mi>
                 D
                </mi>
<mtext>
                 out
                </mtext>
</msub>
<mo separator="true">
                ,
               </mo>
<msub>
<mi>
                 H
                </mi>
<mtext>
                 out
                </mtext>
</msub>
<mo separator="true">
                ,
               </mo>
<msub>
<mi>
                 W
                </mi>
<mtext>
                 out
                </mtext>
</msub>
<mo separator="true">
                ,
               </mo>
<mn>
                3
               </mn>
<mo stretchy="false">
                )
               </mo>
</mrow>
<annotation encoding="application/x-tex">
               (N, D_text{out}, H_text{out}, W_text{out}, 3)
              </annotation>
</semantics>
</math> -->( N , D out , H out , W out , 3 ) (N, D_text{out}, H_text{out}, W_text{out}, 3)( N , D out ​ , H out ​ , W out ​ , 3 )  (5-D case)

* **mode** ( [*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.13)")  ) – interpolation mode to calculate output values `'bilinear'`  | `'nearest'`  | `'bicubic'`  . Default: `'bilinear'`  Note: `mode='bicubic'`  supports only 4-D input.
When `mode='bilinear'`  and the input is 5-D, the interpolation mode
used internally will actually be trilinear. However, when the input is 4-D,
the interpolation mode will legitimately be bilinear.
* **padding_mode** ( [*str*](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.13)")  ) – padding mode for outside grid values `'zeros'`  | `'border'`  | `'reflection'`  . Default: `'zeros'`
* **align_corners** ( [*bool*](https://docs.python.org/3/library/functions.html#bool "(in Python v3.13)") *,* *optional*  ) – Geometrically, we consider the pixels of the
input as squares rather than points.
If set to `True`  , the extrema ( `-1`  and `1`  ) are considered as referring
to the center points of the input’s corner pixels. If set to `False`  , they
are instead considered as referring to the corner points of the input’s corner
pixels, making the sampling more resolution agnostic.
This option parallels the `align_corners`  option in [`interpolate()`](torch.nn.functional.interpolate.html#torch.nn.functional.interpolate "torch.nn.functional.interpolate")  , and so whichever option is used here
should also be used there to resize the input image before grid sampling.
Default: `False`

Returns
:   output Tensor

Return type
:   output ( [Tensor](../tensors.html#torch.Tensor "torch.Tensor")  )

Warning 

When `align_corners = True`  , the grid positions depend on the pixel
size relative to the input image size, and so the locations sampled by [`grid_sample()`](#torch.nn.functional.grid_sample "torch.nn.functional.grid_sample")  will differ for the same input given at different
resolutions (that is, after being upsampled or downsampled).
The default behavior up to version 1.2.0 was `align_corners = True`  .
Since then, the default behavior has been changed to `align_corners = False`  ,
in order to bring it in line with the default for [`interpolate()`](torch.nn.functional.interpolate.html#torch.nn.functional.interpolate "torch.nn.functional.interpolate")  .

Note 

`mode='bicubic'`  is implemented using the [cubic convolution algorithm](https://en.wikipedia.org/wiki/Bicubic_interpolation)  with <!-- MathML: <math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mi>
             α
            </mi>
<mo>
             =
            </mo>
<mo>
             −
            </mo>
<mn>
             0.75
            </mn>
</mrow>
<annotation encoding="application/x-tex">
            alpha=-0.75
           </annotation>
</semantics>
</math> -->α = − 0.75 alpha=-0.75α = − 0.75  .
The constant <!-- MathML: <math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mi>
             α
            </mi>
</mrow>
<annotation encoding="application/x-tex">
            alpha
           </annotation>
</semantics>
</math> -->α alphaα  might be different from packages to packages.
For example, [PIL](https://github.com/python-pillow/Pillow/blob/4634eafe3c695a014267eefdce830b4a825beed7/src/libImaging/Resample.c#L51)  and [OpenCV](https://github.com/opencv/opencv/blob/f345ed564a06178670750bad59526cfa4033be55/modules/imgproc/src/resize.cpp#L908)  use -0.5 and -0.75 respectively.
This algorithm may “overshoot” the range of values it’s interpolating.
For example, it may produce negative values or values greater than 255 when interpolating input in [0, 255].
Clamp the results with [`torch.clamp()`](torch.clamp.html#torch.clamp "torch.clamp")  to ensure they are within the valid range.

